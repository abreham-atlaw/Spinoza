{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from typing import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILES = sorted([os.path.join(\"Data/Minutes\", path) for path in os.listdir(\"Data/Minutes\")[:5]])\n",
    "DATA_PATH = (\"temp/train\", \"temp/test\")\n",
    "SEQ_LEN = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSetTooSmall(Exception):\n",
    "\tpass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreparer:\n",
    "\tdef __init__(\n",
    "\t\t\tself, \n",
    "\t\t\tseq_len, \n",
    "\t\t\tfiles: List[str], \n",
    "\t\t\ttrain_output_path: str,\n",
    "\t\t\ttest_output_path: str,\n",
    "\t\t\ttest_split_ratio: float = 0.1,\n",
    "\t\t\tx_column_headers: List[str] = None, \n",
    "\t\t\ty_column_header: str = \"y\",\n",
    "\t\t\tmax_rows: int = 1000000\n",
    "\t):\n",
    "\t\tself.__seq_len = seq_len\n",
    "\t\tself.__files = files\n",
    "\t\tself.__train_output_path, self.__test_output_path = train_output_path, test_output_path\n",
    "\t\tself.__test_split_ratio = test_split_ratio\n",
    "\t\tself.__max_rows = max_rows\n",
    "\t\tself.__x_column_headers = x_column_headers\n",
    "\t\tif x_column_headers is None:\n",
    "\t\t\tself.__x_column_headers = [str(i) for i in range(seq_len)]\n",
    "\t\tself.__y_column_header = y_column_header\n",
    "\t\t\n",
    "\tdef __get_currency_pairs(self, df: pd.DataFrame) -> List[Tuple[str, str]]:\n",
    "\t\tDELIMITER = \"/\"\n",
    "\t\treturn [\n",
    "\t\t\t(pair.split(DELIMITER)[0], pair.split(DELIMITER)[1]) for pair in\n",
    "\t\t\tset(df[\"base_currency\"] + DELIMITER + df[\"quote_currency\"])\n",
    "\t\t]  # TODO FIND A CLEAR WAY\n",
    "\n",
    "\tdef __prepare_for_pair(self, sequence: np.ndarray, seq_len: int):\n",
    "\t\tdata_len = sequence.shape[0] - seq_len\n",
    "\t\tX = np.zeros((data_len, seq_len))\n",
    "\t\ty = np.zeros((data_len,))\n",
    "\t\tfor i in range(data_len):\n",
    "\t\t\tX[i] = sequence[i:i + seq_len]\n",
    "\t\t\tif sequence[i] > sequence[i - 1]:\n",
    "\t\t\t\ty[i] = 1\n",
    "\t\t\telse:\n",
    "\t\t\t\ty[i] = 0\n",
    "\t\treturn X, y\n",
    "\n",
    "\tdef __prepare_data(self, data: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:\n",
    "\t\tcurrency_pairs = self.__get_currency_pairs(data)\n",
    "\n",
    "\t\tX = []\n",
    "\t\ty = []\n",
    "\n",
    "\t\tfor base_currency, quote_currency in currency_pairs:\n",
    "\t\t\tpair_sequence = data[data[\"base_currency\"] == base_currency][\n",
    "\t\t\t\tdata[data[\"base_currency\"] == base_currency][\"quote_currency\"] == quote_currency\n",
    "\t\t\t][\"c\"].to_numpy()  # TODO\n",
    "\t\t\tpair_X, pair_y = self.__prepare_for_pair(pair_sequence, self.__seq_len)\n",
    "\t\t\tX += list(pair_X)\n",
    "\t\t\ty += list(pair_y)\n",
    "\n",
    "\t\treturn np.array(X), np.array(y)\n",
    "\n",
    "\tdef __split_data(self, X, y) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "\t\treturn train_test_split(X, y, test_size=self.__test_split_ratio, random_state=42)\n",
    "\n",
    "\tdef __load_file(self, file_name: str) -> pd.DataFrame:\n",
    "\t\treturn pd.read_csv(file_name, index_col=0)\n",
    "\n",
    "\tdef __process_file(self, file: str) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "\n",
    "\t\traw_data = self.__load_file(file)\n",
    "\t\tif len(raw_data) < self.__seq_len:\n",
    "\t\t\traise DataSetTooSmall()\n",
    "\t\tX, y = self.__prepare_data(raw_data)\n",
    "\t\tX_train, X_test, y_train, y_test = self.__split_data(X, y)\n",
    "\t\ttrain_df, test_df = pd.DataFrame(X_train, columns=self.__x_column_headers), pd.DataFrame(X_test, columns=self.__x_column_headers)\n",
    "\t\ttrain_df.columns = test_df.columns = self.__x_column_headers\n",
    "\t\ttrain_df[self.__y_column_header], test_df[self.__y_column_header] = pd.DataFrame(y_train), pd.DataFrame(y_test)\n",
    "\t\treturn train_df, test_df\n",
    "\n",
    "\tdef __create_dfs(self) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "\t\treturn tuple([pd.DataFrame(columns=self.__x_column_headers+[self.__y_column_header]) for i in range(2)])\n",
    "\n",
    "\tdef __generate_filename(self) -> str:\n",
    "\t\treturn f\"{datetime.now().timestamp()}.csv\"\n",
    "\t\n",
    "\tdef __save_df(self, df: pd.DataFrame, folder):\n",
    "\t\tdf.to_csv(os.path.join(folder, self.__generate_filename()), index=False)\n",
    "\t\n",
    "\tdef __append_df(self, df: pd.DataFrame, new_data: pd.DataFrame, path: str) -> pd.DataFrame:\n",
    "\t\tif len(df) + len(new_data) <= self.__max_rows:\n",
    "\t\t\treturn df.append(new_data)\n",
    "\t\tbound: int = self.__max_rows - len(df)\n",
    "\t\told_df = self.__append_df(df, new_data.iloc[:bound], path)\n",
    "\t\tself.__save_df(old_df, path)\n",
    "\t\treturn new_data[bound:]\n",
    "\n",
    "\tdef __append_dfs(self, train_dfs: Tuple[pd.DataFrame, pd.DataFrame], test_dfs: Tuple[pd.DataFrame, pd.DataFrame]) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "\t\ttrain_df = self.__append_df(train_dfs[0], train_dfs[1], self.__train_output_path)\n",
    "\t\ttest_df = self.__append_df(test_dfs[0], test_dfs[1], self.__test_output_path)\n",
    "\t\treturn train_df, test_df\n",
    "\t\t\n",
    "\tdef start(self):\n",
    "\t\ttrain_df, test_df = self.__create_dfs()\n",
    "\t\tfor i, file in enumerate(self.__files):\n",
    "\t\t\ttry:\n",
    "\t\t\t\tnew_train_data, new_test_data = self.__process_file(file)\n",
    "\t\t\texcept DataSetTooSmall:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\ttrain_df, test_df = self.__append_dfs(\n",
    "\t\t\t\t(train_df, new_train_data),\n",
    "\t\t\t\t(test_df, new_test_data)\n",
    "\t\t\t)\n",
    "\t\t\tprint(f\"Done: {100*(i+1)/len(self.__files) :.2f}%\\tFinished: {file}\", end=\"\\r\")\n",
    "\t\tself.__save_df(train_df, self.__train_output_path)\n",
    "\t\tself.__save_df(test_df, self.__test_output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: 20.00%\tFinished: Data/Minutes/CAD-TRY.csv\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: 40.00%\tFinished: Data/Minutes/AUD-CHF.csv\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: 60.00%\tFinished: Data/Minutes/AUD-CZK.csv\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: 80.00%\tFinished: Data/Minutes/DKK-GBP.csv\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: 100.00%\tFinished: Data/Minutes/GBP-TRY.csv\r"
     ]
    }
   ],
   "source": [
    "processor = DataPreparer(\n",
    "\tSEQ_LEN,\n",
    "\tFILES,\n",
    "\tDATA_PATH[0],\n",
    "\tDATA_PATH[1]\n",
    ")\n",
    "processor.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
