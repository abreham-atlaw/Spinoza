{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":199105437,"sourceType":"kernelVersion"},{"sourceId":199602130,"sourceType":"kernelVersion"},{"sourceId":199602285,"sourceType":"kernelVersion"},{"sourceId":199602296,"sourceType":"kernelVersion"}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!rm -fr r_trader out\n!mkdir out\n!git clone https://github.com/abreham-atlaw/r_trader\n!cd r_trader &&  git checkout deep-reinforcement.training-experiment-linear\n!pip install cattrs positional-encodings==6.0.1 dropbox==11.27.0 pymongo==4.3.3 dependency-injector==4.41.0","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-31T09:02:01.845346Z","iopub.execute_input":"2024-10-31T09:02:01.845729Z","iopub.status.idle":"2024-10-31T09:02:33.489394Z","shell.execute_reply.started":"2024-10-31T09:02:01.845699Z","shell.execute_reply":"2024-10-31T09:02:33.488219Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'r_trader'...\nremote: Enumerating objects: 12930, done.\u001b[K\nremote: Counting objects: 100% (3844/3844), done.\u001b[K\nremote: Compressing objects: 100% (1073/1073), done.\u001b[K\nremote: Total 12930 (delta 2830), reused 3767 (delta 2753), pack-reused 9086 (from 1)\u001b[K\nReceiving objects: 100% (12930/12930), 76.53 MiB | 11.92 MiB/s, done.\nResolving deltas: 100% (9162/9162), done.\nBranch 'deep-reinforcement.training-experiment-linear' set up to track remote branch 'deep-reinforcement.training-experiment-linear' from 'origin'.\nSwitched to a new branch 'deep-reinforcement.training-experiment-linear'\nCollecting cattrs\n  Downloading cattrs-24.1.2-py3-none-any.whl.metadata (8.4 kB)\nCollecting positional-encodings==6.0.1\n  Downloading positional_encodings-6.0.1-py3-none-any.whl.metadata (6.6 kB)\nCollecting dropbox==11.27.0\n  Downloading dropbox-11.27.0-py3-none-any.whl.metadata (4.2 kB)\nCollecting pymongo==4.3.3\n  Downloading pymongo-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.6 kB)\nCollecting dependency-injector==4.41.0\n  Downloading dependency_injector-4.41.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from positional-encodings==6.0.1) (1.26.4)\nRequirement already satisfied: requests>=2.16.2 in /opt/conda/lib/python3.10/site-packages (from dropbox==11.27.0) (2.31.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from dropbox==11.27.0) (1.16.0)\nCollecting stone>=2.* (from dropbox==11.27.0)\n  Downloading stone-3.3.8-py3-none-any.whl.metadata (8.0 kB)\nCollecting dnspython<3.0.0,>=1.16.0 (from pymongo==4.3.3)\n  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: attrs>=23.1.0 in /opt/conda/lib/python3.10/site-packages (from cattrs) (23.2.0)\nRequirement already satisfied: exceptiongroup>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from cattrs) (1.2.0)\nRequirement already satisfied: typing-extensions!=4.6.3,>=4.1.0 in /opt/conda/lib/python3.10/site-packages (from cattrs) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.16.2->dropbox==11.27.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.16.2->dropbox==11.27.0) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.16.2->dropbox==11.27.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.16.2->dropbox==11.27.0) (2024.2.2)\nCollecting ply>=3.4 (from stone>=2.*->dropbox==11.27.0)\n  Downloading ply-3.11-py2.py3-none-any.whl.metadata (844 bytes)\nRequirement already satisfied: packaging>=21.0 in /opt/conda/lib/python3.10/site-packages (from stone>=2.*->dropbox==11.27.0) (21.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21.0->stone>=2.*->dropbox==11.27.0) (3.1.1)\nDownloading positional_encodings-6.0.1-py3-none-any.whl (7.5 kB)\nDownloading dropbox-11.27.0-py3-none-any.whl (582 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m582.5/582.5 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pymongo-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (492 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.9/492.9 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading dependency_injector-4.41.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading cattrs-24.1.2-py3-none-any.whl (66 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading stone-3.3.8-py3-none-any.whl (159 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.0/159.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ply-3.11-py2.py3-none-any.whl (49 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[33mDEPRECATION: dropbox 11.27.0 has a non-standard dependency specifier stone>=2.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of dropbox or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n\u001b[0mInstalling collected packages: ply, positional-encodings, dnspython, dependency-injector, cattrs, stone, pymongo, dropbox\n  Attempting uninstall: pymongo\n    Found existing installation: pymongo 3.13.0\n    Uninstalling pymongo-3.13.0:\n      Successfully uninstalled pymongo-3.13.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.2 which is incompatible.\napache-beam 2.46.0 requires pymongo<4.0.0,>=3.8.0, but you have pymongo 4.3.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed cattrs-24.1.2 dependency-injector-4.41.0 dnspython-2.7.0 dropbox-11.27.0 ply-3.11 positional-encodings-6.0.1 pymongo-4.3.3 stone-3.3.8\n","output_type":"stream"}]},{"cell_type":"code","source":"import sys\nsys.path.append(\"/kaggle/working/r_trader\")","metadata":{"execution":{"iopub.status.busy":"2024-10-31T09:02:33.492046Z","iopub.execute_input":"2024-10-31T09:02:33.493060Z","iopub.status.idle":"2024-10-31T09:02:33.498719Z","shell.execute_reply.started":"2024-10-31T09:02:33.493012Z","shell.execute_reply":"2024-10-31T09:02:33.497311Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torch.optim import Adam, SGD, Adagrad\nimport matplotlib.pyplot as plt\n\nimport os\nimport signal \n\nfrom core.utils.research.data.load.dataset import BaseDataset\nfrom core.utils.research.training.trainer import Trainer\nfrom core.utils.research.model.model.cnn.model import CNN\nfrom core.utils.research.model.model.linear.model import LinearModel\nfrom lib.utils.torch_utils.model_handler import ModelHandler\nfrom core.utils.research.training.callbacks.checkpoint_callback import CheckpointCallback, StoreCheckpointCallback\nfrom core.utils.research.training.data.repositories.checkpoint_repository import CheckpointRepository\nfrom lib.utils.file_storage import PCloudClient\nfrom core.utils.research.training.data.state import TrainingState\nfrom core import Config\nfrom core.utils.research.training.callbacks.metric_callback import MetricCallback\nfrom core.utils.research.training.data.repositories.metric_repository import MetricRepository, MongoDBMetricRepository\nfrom core.utils.kaggle import FusedManager\nfrom core.di import init_di, ApplicationContainer\nfrom core.utils.research.training.data.metric import MetricsContainer\nfrom core.utils.research.model.layers import Indicators\nfrom core.di import ServiceProvider\nfrom core.utils.research.losses import OutputBatchVarianceLoss, MultiLoss\nfrom core.utils.kaggle.data_repository import KaggleDataRepository","metadata":{"execution":{"iopub.status.busy":"2024-10-31T09:02:33.500241Z","iopub.execute_input":"2024-10-31T09:02:33.500578Z","iopub.status.idle":"2024-10-31T09:02:39.303289Z","shell.execute_reply.started":"2024-10-31T09:02:33.500551Z","shell.execute_reply":"2024-10-31T09:02:39.301930Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"KAGGLE_ENV = os.path.exists(\"/kaggle/input\")\n\nDATA_ROOT = \"/kaggle/input\" if KAGGLE_ENV else \"/content/input\"\n\nDATASETS = [\n    f\"abrehamatlaw0/spinoza-ds-datapreparer-simsim-cum-0-it-2-{i}\"\n    for i in range(0,4)\n]\nCHECKSUMS = None\nKERNEL_MODE = False\nZIP_FILENAME = \"out.zip\"\nif not KAGGLE_ENV:\n    download_data(DATA_ROOT, DATASETS, ZIP_FILENAME, kernel_mode=KERNEL_MODE, checksums=CHECKSUMS)\n\n\nCONTAINERS = [os.path.join(DATA_ROOT, container) for container in os.listdir(DATA_ROOT)]\nDATA_PATHES, TEST_DATA_PATHES = [\n    [\n        os.path.join(container, \"out\", type_)\n        for container in CONTAINERS\n    ]\n    for type_ in [\"train\", \"test\"]\n]\n\nNOTEBOOK_ID = \"abrehamalemu/rtrader-training-exp-0-linear-124-cum-0-it-4-tot\"\nMODEL_ID = NOTEBOOK_ID.replace(\"/\", \"-\")\n\nNUM_FILES = None\nDATA_CACHE_SIZE = 2\nDATALOADER_WORKERS = 4\n\nVOCAB_SIZE = 431\nDROPOUT = 0.3\nLAYER_SIZES = [512 for _ in range(5)] + [VOCAB_SIZE + 1]\nHIDDEN_ACTIVATION = nn.LeakyReLU()\nINIT_FUNCTION = None\nNORM = [True] + [False for _ in LAYER_SIZES[1:]]\nBLOCK_SIZE = 1148\nLR = 1e-4\nLOSS_WEIGHTS = [0.7, 0.3]\n\nBATCH_SIZE = 64\nEPOCHS = 300\nTIMEOUT = 10*60*60\n\nDTYPE = torch.float32\nNP_DTYPE = np.float32\n\nMODEL_URL = None\nSAVE_PATH = os.path.abspath(\"./out/model.zip\")\nSTATE_SAVE_PATH = os.path.abspath(\"./out/model.zip\")\n\nMETRIC_REPOSITORY = MongoDBMetricRepository(\n    Config.MONGODB_URL,\n    MODEL_ID\n)\n\nCALLBACKS = [\n    StoreCheckpointCallback(path=SAVE_PATH),\n    MetricCallback(\n       METRIC_REPOSITORY\n    )\n]","metadata":{"execution":{"iopub.status.busy":"2024-10-31T09:02:39.305947Z","iopub.execute_input":"2024-10-31T09:02:39.306494Z","iopub.status.idle":"2024-10-31T09:02:39.357102Z","shell.execute_reply.started":"2024-10-31T09:02:39.306461Z","shell.execute_reply":"2024-10-31T09:02:39.355951Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"repository = CheckpointRepository(\n    ServiceProvider.provide_file_storage()\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T09:02:39.358332Z","iopub.execute_input":"2024-10-31T09:02:39.358659Z","iopub.status.idle":"2024-10-31T09:02:39.392468Z","shell.execute_reply.started":"2024-10-31T09:02:39.358630Z","shell.execute_reply":"2024-10-31T09:02:39.391453Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"state_model = repository.get(MODEL_ID)\n# state_model = None\nif state_model is None:\n    print(\"[+]Creating a new model...\")\n    \n    model = LinearModel(\n        dropout_rate=DROPOUT,\n        layer_sizes=LAYER_SIZES,\n        hidden_activation=HIDDEN_ACTIVATION,\n        init_fn=INIT_FUNCTION,\n        norm=NORM,\n        input_size=BLOCK_SIZE\n    )\n    \nelse:\n    print(\"[+]Using loaded model...\")\n    state, model = state_model\nstate = TrainingState(\n    epoch=0,\n    batch=0,\n    id=MODEL_ID\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T09:02:39.393672Z","iopub.execute_input":"2024-10-31T09:02:39.394013Z","iopub.status.idle":"2024-10-31T09:02:40.931557Z","shell.execute_reply.started":"2024-10-31T09:02:39.393984Z","shell.execute_reply":"2024-10-31T09:02:40.930328Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"[+]Creating a new model...\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset = BaseDataset(\n    root_dirs=DATA_PATHES,\n    out_dtypes=NP_DTYPE,\n    num_files=NUM_FILES\n)\ndataloader = DataLoader(dataset, batch_size=BATCH_SIZE, num_workers=DATALOADER_WORKERS, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T09:02:40.932830Z","iopub.execute_input":"2024-10-31T09:02:40.933213Z","iopub.status.idle":"2024-10-31T09:02:42.185212Z","shell.execute_reply.started":"2024-10-31T09:02:40.933182Z","shell.execute_reply":"2024-10-31T09:02:42.183884Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"test_dataset = BaseDataset(\n    root_dirs=TEST_DATA_PATHES, \n    out_dtypes=NP_DTYPE,\n    num_files=NUM_FILES\n)\ntest_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=DATALOADER_WORKERS, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T09:02:42.187351Z","iopub.execute_input":"2024-10-31T09:02:42.188068Z","iopub.status.idle":"2024-10-31T09:02:43.307539Z","shell.execute_reply.started":"2024-10-31T09:02:42.188020Z","shell.execute_reply":"2024-10-31T09:02:43.306377Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(model, callbacks=CALLBACKS)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T09:02:43.309094Z","iopub.execute_input":"2024-10-31T09:02:43.309456Z","iopub.status.idle":"2024-10-31T09:02:43.319326Z","shell.execute_reply.started":"2024-10-31T09:02:43.309427Z","shell.execute_reply":"2024-10-31T09:02:43.318175Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"trainer.cls_loss_function = MultiLoss(\n    losses = [\n        nn.CrossEntropyLoss(),\n        OutputBatchVarianceLoss()\n    ],\n    weights = LOSS_WEIGHTS,\n    device=trainer.device\n)\ntrainer.reg_loss_function = nn.MSELoss()\ntrainer.optimizer = Adam(trainer.model.parameters(), lr=LR)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T09:02:43.323878Z","iopub.execute_input":"2024-10-31T09:02:43.324568Z","iopub.status.idle":"2024-10-31T09:02:45.968608Z","shell.execute_reply.started":"2024-10-31T09:02:43.324530Z","shell.execute_reply":"2024-10-31T09:02:45.967472Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class TimeoutException(Exception):\n    pass\n\ndef handle_timeout(*args, **kwargs):\n    raise TimeoutException()\n\nsignal.signal(signal.SIGALRM, handle_timeout)\nsignal.alarm(TIMEOUT)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T09:02:45.970248Z","iopub.execute_input":"2024-10-31T09:02:45.971481Z","iopub.status.idle":"2024-10-31T09:02:45.980266Z","shell.execute_reply.started":"2024-10-31T09:02:45.971433Z","shell.execute_reply":"2024-10-31T09:02:45.979197Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"try:\n    trainer.train(dataloader, val_dataloader=test_dataloader, epochs=EPOCHS, progress=True, progress_interval=100, state=state, cls_loss_only=False)\nexcept TimeoutException:\n    pass","metadata":{"execution":{"iopub.status.busy":"2024-10-31T09:02:45.981648Z","iopub.execute_input":"2024-10-31T09:02:45.982100Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Model Summary\nLayer Name\t\t\t\t\t\t\tNumber of Parameters\n====================================================================================================\nlayers.0.weight\t\t\t587776\nlayers.0.bias\t\t\t512\nlayers.1.weight\t\t\t262144\nlayers.1.bias\t\t\t512\nlayers.2.weight\t\t\t262144\nlayers.2.bias\t\t\t512\nlayers.3.weight\t\t\t262144\nlayers.3.bias\t\t\t512\nlayers.4.weight\t\t\t262144\nlayers.4.bias\t\t\t512\nlayers.5.weight\t\t\t221184\nlayers.5.bias\t\t\t432\nnorms.0.weight\t\t\t1148\nnorms.0.bias\t\t\t1148\n====================================================================================================\nTotal Params:1862824\n[+]Shuffling dataset...\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/32310 [00:00<?, ?it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nEpoch 1 loss: 43.71457290649414(cls: 43.605010986328125, reg: 0.10955387353897095):   1%|          | 173/32310 [00:04<12:40, 42.23it/s]","output_type":"stream"}]},{"cell_type":"code","source":"ModelHandler.save(model, SAVE_PATH)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"repository.update(trainer.state, trainer.model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics = MetricsContainer()\nfor metric in METRIC_REPOSITORY.get_all():\n    metrics.add_metric(metric)\n\nfor i in range(3):\n    train_losses = [metric.value[i] for metric in metrics.filter_metrics(source=0)]\n    val_losses = [metric.value[i] for metric in metrics.filter_metrics(source=1)]\n    plt.figure()\n    plt.plot(train_losses)\n    plt.plot(val_losses)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for X, y in test_dataloader:\n    break\ny_hat = model(X.to(trainer.device)).detach().cpu().numpy()\n\nimport matplotlib.pyplot as plt\ndef softmax(x):\n    exp_x = np.exp(x - np.max(x))\n    softmax_x = exp_x / np.sum(exp_x)\n    return softmax_x\n\ndef scale(x):\n    x = softmax(x)\n    x = x / np.max(x)\n    return x\n\nfor i in range(y_hat.shape[0]):\n    plt.figure()\n    plt.plot(y[i, :-1])\n    plt.plot(scale(y_hat[i, :-1]))\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -fr r_trader","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}