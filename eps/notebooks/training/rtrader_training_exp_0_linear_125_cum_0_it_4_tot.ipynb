{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 199105437,
          "sourceType": "kernelVersion"
        },
        {
          "sourceId": 199602130,
          "sourceType": "kernelVersion"
        },
        {
          "sourceId": 199602285,
          "sourceType": "kernelVersion"
        },
        {
          "sourceId": 199602296,
          "sourceType": "kernelVersion"
        }
      ],
      "dockerImageVersionId": 30673,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!rm -fr r_trader out\n",
        "!mkdir out input\n",
        "!git clone https://github.com/abreham-atlaw/r_trader\n",
        "!cd r_trader &&  git checkout deep-reinforcement.training-experiment-linear\n",
        "!pip install cattrs positional-encodings==6.0.1 dropbox pymongo==4.3.3 dependency-injector==4.41.0"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "ZsrxkaEM5YCo",
        "outputId": "1f01cfff-45b4-48c8-a20d-996e8c0b20b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'r_trader'...\n",
            "remote: Enumerating objects: 12948, done.\u001b[K\n",
            "remote: Counting objects: 100% (3862/3862), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1078/1078), done.\u001b[K\n",
            "remote: Total 12948 (delta 2838), reused 3784 (delta 2760), pack-reused 9086 (from 1)\u001b[K\n",
            "Receiving objects: 100% (12948/12948), 76.54 MiB | 19.61 MiB/s, done.\n",
            "Resolving deltas: 100% (9170/9170), done.\n",
            "Branch 'deep-reinforcement.training-experiment-linear' set up to track remote branch 'deep-reinforcement.training-experiment-linear' from 'origin'.\n",
            "Switched to a new branch 'deep-reinforcement.training-experiment-linear'\n",
            "Requirement already satisfied: cattrs in /usr/local/lib/python3.10/dist-packages (24.1.2)\n",
            "Requirement already satisfied: positional-encodings==6.0.1 in /usr/local/lib/python3.10/dist-packages (6.0.1)\n",
            "Requirement already satisfied: dropbox in /usr/local/lib/python3.10/dist-packages (12.0.2)\n",
            "Requirement already satisfied: pymongo==4.3.3 in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: dependency-injector==4.41.0 in /usr/local/lib/python3.10/dist-packages (4.41.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from positional-encodings==6.0.1) (1.26.4)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo==4.3.3) (2.7.0)\n",
            "Requirement already satisfied: six<=1.16.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from dependency-injector==4.41.0) (1.16.0)\n",
            "Requirement already satisfied: attrs>=23.1.0 in /usr/local/lib/python3.10/dist-packages (from cattrs) (24.2.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from cattrs) (1.2.2)\n",
            "Requirement already satisfied: typing-extensions!=4.6.3,>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from cattrs) (4.12.2)\n",
            "Requirement already satisfied: requests>=2.16.2 in /usr/local/lib/python3.10/dist-packages (from dropbox) (2.32.3)\n",
            "Requirement already satisfied: stone<3.3.3,>=2 in /usr/local/lib/python3.10/dist-packages (from dropbox) (3.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.16.2->dropbox) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.16.2->dropbox) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.16.2->dropbox) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.16.2->dropbox) (2024.8.30)\n",
            "Requirement already satisfied: ply>=3.4 in /usr/local/lib/python3.10/dist-packages (from stone<3.3.3,>=2->dropbox) (3.11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "KAGGLE_ENV = os.path.exists(\"/kaggle/working\")\n",
        "REPO_PATH = \"/kaggle/working/r_trader\" if KAGGLE_ENV else \"/content/r_trader\"\n",
        "\n",
        "print(f\"KAGGLE ENV: {KAGGLE_ENV}\")\n",
        "\n",
        "import sys\n",
        "sys.path.append(REPO_PATH)"
      ],
      "metadata": {
        "trusted": true,
        "id": "HRcF22a15YCs",
        "outputId": "f56b3854-804f-4d4d-8cd4-9dc4a807954d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KAGGLE ENV: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam, SGD, Adagrad\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import signal\n",
        "\n",
        "from core.utils.research.data.load.dataset import BaseDataset\n",
        "from core.utils.research.training.trainer import Trainer\n",
        "from core.utils.research.model.model.cnn.model import CNN\n",
        "from core.utils.research.model.model.linear.model import LinearModel\n",
        "from lib.utils.torch_utils.model_handler import ModelHandler\n",
        "from core.utils.research.training.callbacks.checkpoint_callback import CheckpointCallback, StoreCheckpointCallback\n",
        "from core.utils.research.training.data.repositories.checkpoint_repository import CheckpointRepository\n",
        "from lib.utils.file_storage import PCloudClient\n",
        "from core.utils.research.training.data.state import TrainingState\n",
        "from core import Config\n",
        "from core.utils.research.training.callbacks.metric_callback import MetricCallback\n",
        "from core.utils.research.training.data.repositories.metric_repository import MetricRepository, MongoDBMetricRepository\n",
        "from core.utils.kaggle import FusedManager\n",
        "from core.di import init_di, ApplicationContainer\n",
        "from core.utils.research.training.data.metric import MetricsContainer\n",
        "from core.utils.research.model.layers import Indicators\n",
        "from core.di import ServiceProvider\n",
        "from core.utils.kaggle.data_repository import KaggleDataRepository"
      ],
      "metadata": {
        "trusted": true,
        "id": "-PHbK03b5YCu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_data(root, datasets, zip_filename, kernel_mode=True, checksums=None):\n",
        "    repository = KaggleDataRepository(\n",
        "        output_path=root,\n",
        "        zip_filename=zip_filename\n",
        "    )\n",
        "    repository.download_multiple(datasets, kernel=kernel_mode, checksums=checksums)\n",
        "    os.system(f\"unzip -d root/\")"
      ],
      "metadata": {
        "id": "P66VhSdK5ccf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_ROOT = \"/kaggle/input\" if KAGGLE_ENV else \"/content/input\"\n",
        "\n",
        "DATASETS = [\n",
        "    f\"abrehamatlaw0/spinoza-ds-datapreparer-simsim-cum-0-it-2-{i}\"\n",
        "    for i in range(0,4)\n",
        "]\n",
        "CHECKSUMS = None\n",
        "KERNEL_MODE = False\n",
        "ZIP_FILENAME = \"out.zip\"\n",
        "if not KAGGLE_ENV:\n",
        "    download_data(DATA_ROOT, DATASETS, ZIP_FILENAME, kernel_mode=KERNEL_MODE, checksums=CHECKSUMS)\n",
        "\n",
        "\n",
        "CONTAINERS = [os.path.join(DATA_ROOT, container) for container in os.listdir(DATA_ROOT)]\n",
        "DATA_PATHES, TEST_DATA_PATHES = [\n",
        "    [\n",
        "        os.path.join(container, \"out\", type_)\n",
        "        for container in CONTAINERS\n",
        "    ]\n",
        "    for type_ in [\"train\", \"test\"]\n",
        "]\n",
        "\n",
        "NOTEBOOK_ID = \"abrehamalemu/rtrader-training-exp-0-linear-125-cum-0-it-4-tot\"\n",
        "MODEL_ID = NOTEBOOK_ID.replace(\"/\", \"-\")\n",
        "\n",
        "NUM_FILES = None\n",
        "DATA_CACHE_SIZE = 2\n",
        "DATALOADER_WORKERS = 4\n",
        "\n",
        "VOCAB_SIZE = 431\n",
        "DROPOUT = 0.3\n",
        "LAYER_SIZES = [4096 for _ in range(10)] + [VOCAB_SIZE + 1]\n",
        "HIDDEN_ACTIVATION = nn.LeakyReLU()\n",
        "INIT_FUNCTION = None\n",
        "NORM = [True] + [False for _ in LAYER_SIZES[1:]]\n",
        "BLOCK_SIZE = 1148\n",
        "LR = 1e-6\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 100\n",
        "TIMEOUT = int(10*60*60)\n",
        "\n",
        "DTYPE = torch.float32\n",
        "NP_DTYPE = np.float32\n",
        "\n",
        "MODEL_URL = None\n",
        "SAVE_PATH = os.path.abspath(\"./out/model.zip\")\n",
        "STATE_SAVE_PATH = os.path.abspath(\"./out/model.zip\")\n",
        "\n",
        "METRIC_REPOSITORY = MongoDBMetricRepository(\n",
        "    Config.MONGODB_URL,\n",
        "    MODEL_ID\n",
        ")\n",
        "\n",
        "CALLBACKS = [\n",
        "    StoreCheckpointCallback(path=SAVE_PATH),\n",
        "    MetricCallback(\n",
        "       METRIC_REPOSITORY\n",
        "    )\n",
        "]"
      ],
      "metadata": {
        "trusted": true,
        "id": "jUXAEAJE5YCx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repository = CheckpointRepository(\n",
        "    ServiceProvider.provide_file_storage()\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "XTR4AZGa5YC0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state_model = repository.get(MODEL_ID)\n",
        "# state_model = None\n",
        "if state_model is None:\n",
        "    print(\"[+]Creating a new model...\")\n",
        "\n",
        "    model = LinearModel(\n",
        "        dropout_rate=DROPOUT,\n",
        "        layer_sizes=LAYER_SIZES,\n",
        "        hidden_activation=HIDDEN_ACTIVATION,\n",
        "        init_fn=INIT_FUNCTION,\n",
        "        norm=NORM,\n",
        "        input_size=BLOCK_SIZE\n",
        "    )\n",
        "\n",
        "else:\n",
        "    print(\"[+]Using loaded model...\")\n",
        "    state, model = state_model\n",
        "state = TrainingState(\n",
        "    epoch=0,\n",
        "    batch=0,\n",
        "    id=MODEL_ID\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "to_snny15YC1",
        "outputId": "aed2377b-d3c7-4c3c-d393-89b7a9845a4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[+]Creating a new model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = BaseDataset(\n",
        "    root_dirs=DATA_PATHES,\n",
        "    out_dtypes=NP_DTYPE,\n",
        "    num_files=NUM_FILES\n",
        ")\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, num_workers=DATALOADER_WORKERS, pin_memory=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "6J3NFG-z5YC2",
        "outputId": "1599f8d5-0701-4588-9180-3ba28071cd72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-0fe90fe9a8bd>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m dataset = BaseDataset(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mroot_dirs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDATA_PATHES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mout_dtypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNP_DTYPE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnum_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_FILES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;32m/content/r_trader/core/utils/research/data/load/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root_dirs, cache_size, X_dir, y_dir, out_dtypes, num_files)\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_points_per_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_dp_per_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/r_trader/core/utils/research/data/load/dataset.py\u001b[0m in \u001b[0;36m__get_dp_per_file\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__get_dp_per_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mfirst_file_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m                 \u001b[0mfirst_file_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_dirs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__X_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_file_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfirst_file_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = BaseDataset(\n",
        "    root_dirs=TEST_DATA_PATHES,\n",
        "    out_dtypes=NP_DTYPE,\n",
        "    num_files=NUM_FILES\n",
        ")\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=DATALOADER_WORKERS, pin_memory=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "ePlmocwk5YC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(model, callbacks=CALLBACKS)"
      ],
      "metadata": {
        "trusted": true,
        "id": "zARpDufj5YC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.cls_loss_function = nn.CrossEntropyLoss()\n",
        "trainer.reg_loss_function = nn.MSELoss()\n",
        "trainer.optimizer = Adam(trainer.model.parameters(), lr=LR)"
      ],
      "metadata": {
        "trusted": true,
        "id": "PGb8KkRU5YC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeoutException(Exception):\n",
        "    pass\n",
        "\n",
        "def handle_timeout(*args, **kwargs):\n",
        "    raise TimeoutException()\n",
        "\n",
        "signal.signal(signal.SIGALRM, handle_timeout)\n",
        "signal.alarm(TIMEOUT)"
      ],
      "metadata": {
        "trusted": true,
        "id": "zV9e76nV5YC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    trainer.train(dataloader, val_dataloader=test_dataloader, epochs=EPOCHS, progress=True, progress_interval=100, state=state, cls_loss_only=False)\n",
        "except TimeoutException:\n",
        "    pass"
      ],
      "metadata": {
        "trusted": true,
        "id": "NEuj3VJS5YC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ModelHandler.save(model, SAVE_PATH)"
      ],
      "metadata": {
        "trusted": true,
        "id": "UynXn4Po5YC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repository.update(trainer.state, trainer.model)"
      ],
      "metadata": {
        "trusted": true,
        "id": "88NnFZLI5YC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = MetricsContainer()\n",
        "for metric in METRIC_REPOSITORY.get_all():\n",
        "    metrics.add_metric(metric)\n",
        "\n",
        "for i in range(3):\n",
        "    train_losses = [metric.value[i] for metric in metrics.filter_metrics(source=0)]\n",
        "    val_losses = [metric.value[i] for metric in metrics.filter_metrics(source=1)]\n",
        "    plt.figure()\n",
        "    plt.plot(train_losses)\n",
        "    plt.plot(val_losses)\n",
        "    plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "97Vt4hGv5YC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for X, y in test_dataloader:\n",
        "    break\n",
        "y_hat = model(X.to(trainer.device)).detach().cpu().numpy()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "def softmax(x):\n",
        "    exp_x = np.exp(x - np.max(x))\n",
        "    softmax_x = exp_x / np.sum(exp_x)\n",
        "    return softmax_x\n",
        "\n",
        "def scale(x):\n",
        "    x = softmax(x)\n",
        "    x = x / np.max(x)\n",
        "    return x\n",
        "\n",
        "for i in range(y_hat.shape[0]):\n",
        "    plt.figure()\n",
        "    plt.plot(y[i, :-1])\n",
        "    plt.plot(scale(y_hat[i, :-1]))\n",
        ""
      ],
      "metadata": {
        "trusted": true,
        "id": "rHmUgHql5YC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -fr r_trader"
      ],
      "metadata": {
        "trusted": true,
        "id": "CdjgN8df5YC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "sT2hU8Yv5YDA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}