{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CMnDGVFyK-lJ",
    "outputId": "1deef265-f55a-4777-de8b-f36fe77c7a7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'r_trader'...\n",
      "remote: Enumerating objects: 16822, done.\u001b[K\n",
      "remote: Counting objects: 100% (315/315), done.\u001b[K\n",
      "remote: Compressing objects: 100% (193/193), done.\u001b[K\n",
      "remote: Total 16822 (delta 208), reused 187 (delta 112), pack-reused 16507 (from 2)\u001b[K\n",
      "Receiving objects: 100% (16822/16822), 77.87 MiB | 21.37 MiB/s, done.\n",
      "Resolving deltas: 100% (12073/12073), done.\n",
      "Branch 'deep-reinforcement.training-experiment-cnn' set up to track remote branch 'deep-reinforcement.training-experiment-cnn' from 'origin'.\n",
      "Switched to a new branch 'deep-reinforcement.training-experiment-cnn'\n",
      "Collecting cattrs\n",
      "  Downloading cattrs-24.1.2-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting positional-encodings==6.0.1\n",
      "  Downloading positional_encodings-6.0.1-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting dropbox\n",
      "  Downloading dropbox-12.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting pymongo==4.3.3\n",
      "  Downloading pymongo-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.6 kB)\n",
      "Collecting dependency-injector==4.41.0\n",
      "  Downloading dependency_injector-4.41.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from positional-encodings==6.0.1) (1.26.4)\n",
      "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo==4.3.3)\n",
      "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting six<=1.16.0,>=1.7.0 (from dependency-injector==4.41.0)\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: attrs>=23.1.0 in /usr/local/lib/python3.11/dist-packages (from cattrs) (24.3.0)\n",
      "Requirement already satisfied: requests>=2.16.2 in /usr/local/lib/python3.11/dist-packages (from dropbox) (2.32.3)\n",
      "Collecting stone<3.3.3,>=2 (from dropbox)\n",
      "  Downloading stone-3.3.1-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.16.2->dropbox) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.16.2->dropbox) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.16.2->dropbox) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.16.2->dropbox) (2024.12.14)\n",
      "Requirement already satisfied: ply>=3.4 in /usr/local/lib/python3.11/dist-packages (from stone<3.3.3,>=2->dropbox) (3.11)\n",
      "Downloading positional_encodings-6.0.1-py3-none-any.whl (7.5 kB)\n",
      "Downloading pymongo-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (494 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.9/494.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dependency_injector-4.41.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cattrs-24.1.2-py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dropbox-12.0.2-py3-none-any.whl (572 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m572.1/572.1 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading stone-3.3.1-py3-none-any.whl (162 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.3/162.3 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: six, positional-encodings, dnspython, cattrs, stone, pymongo, dependency-injector, dropbox\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.17.0\n",
      "    Uninstalling six-1.17.0:\n",
      "      Successfully uninstalled six-1.17.0\n",
      "Successfully installed cattrs-24.1.2 dependency-injector-4.41.0 dnspython-2.7.0 dropbox-12.0.2 positional-encodings-6.0.1 pymongo-4.3.3 six-1.16.0 stone-3.3.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "98a04740dde145a6b9aaa5bd0603d409",
       "pip_warning": {
        "packages": [
         "six"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!rm -fr r_trader out\n",
    "!mkdir out input\n",
    "!git clone https://github.com/abreham-atlaw/r_trader\n",
    "!cd r_trader &&  git checkout main\n",
    "!pip install cattrs positional-encodings==6.0.1 dropbox pymongo==4.3.3 dependency-injector==4.41.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SetxpdI2K-lN",
    "outputId": "f01c9cd2-d70d-498f-ba6a-7a6cbee012f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KAGGLE ENV: False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "KAGGLE_ENV = os.path.exists(\"/kaggle/working\")\n",
    "REPO_PATH = \"/kaggle/working/r_trader\" if KAGGLE_ENV else \"/content/r_trader\"\n",
    "\n",
    "print(f\"KAGGLE ENV: {KAGGLE_ENV}\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(REPO_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kIDpPNaSK-lP",
    "outputId": "48cb5e7a-defd-405c-d2b1-e1d83047b19c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m PID:191 [2025-01-24 07:18:26.549257]  XLA is not installed. Training using TPU will not be possible. \u001b[93m \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam, SGD, Adagrad\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import signal\n",
    "\n",
    "from core.utils.research.data.load.dataset import BaseDataset\n",
    "from core.utils.research.training.trainer import Trainer\n",
    "from core.utils.research.model.model.cnn.model import CNN\n",
    "from core.utils.research.model.model.linear.model import LinearModel\n",
    "from lib.utils.torch_utils.model_handler import ModelHandler\n",
    "from core.utils.research.training.callbacks.checkpoint_callback import CheckpointCallback, StoreCheckpointCallback\n",
    "from core.utils.research.training.data.repositories.checkpoint_repository import CheckpointRepository\n",
    "from lib.utils.file_storage import PCloudClient\n",
    "from core.utils.research.training.data.state import TrainingState\n",
    "from core import Config\n",
    "from core.utils.research.training.callbacks.metric_callback import MetricCallback\n",
    "from core.utils.research.training.data.repositories.metric_repository import MetricRepository, MongoDBMetricRepository\n",
    "from core.utils.kaggle import FusedManager\n",
    "from core.di import init_di, ApplicationContainer\n",
    "from core.utils.research.training.data.metric import MetricsContainer\n",
    "from core.utils.research.model.layers import Indicators\n",
    "from core.di import ServiceProvider\n",
    "from core.utils.kaggle.data_repository import KaggleDataRepository\n",
    "from core.utils.research.losses import ProximalMaskedLoss, MeanSquaredErrorLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "zvBFwwe0K-lQ"
   },
   "outputs": [],
   "source": [
    "def download_data(root, datasets, zip_filename, kernel_mode=True, checksums=None):\n",
    "    repository = KaggleDataRepository(\n",
    "        output_path=root,\n",
    "        zip_filename=zip_filename\n",
    "    )\n",
    "    repository.download_multiple(datasets, kernel=kernel_mode, checksums=checksums)\n",
    "    os.system(f\"unzip -d root/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2tWqyTaGK-lR",
    "outputId": "ad49ee7d-b8ba-4607-aa6e-8100170e6cfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m PID:191 [2025-01-24 07:18:26.626732]  Downloading abrehamatlaw0/spinoza-ds-datapreparer-simsim-cum-0-it-2-0 \u001b[0m\n",
      "\u001b[94m PID:191 [2025-01-24 07:18:26.629175]  Downloading to /content/input/abrehamatlaw0-spinoza-ds-datapreparer-simsim-cum-0-it-2-0 \u001b[0m\n",
      "\u001b[94m PID:191 [2025-01-24 07:18:26.632301]  Checking pre-downloaded for /content/input/abrehamatlaw0-spinoza-ds-datapreparer-simsim-cum-0-it-2-0 \u001b[0m\n",
      "\u001b[94m PID:191 [2025-01-24 07:18:26.632455]  Cleaning /content/input/abrehamatlaw0-spinoza-ds-datapreparer-simsim-cum-0-it-2-0 \u001b[0m\n",
      "\u001b[94m PID:191 [2025-01-24 07:18:29.389410]  Using Account: bemnetatlaw \u001b[0m\n",
      "Dataset URL: https://www.kaggle.com/datasets/abrehamatlaw0/spinoza-ds-datapreparer-simsim-cum-0-it-2-0\n",
      "\u001b[94m PID:191 [2025-01-24 07:18:31.971698]  Unzipping Data... \u001b[0m\n",
      "\u001b[94m PID:191 [2025-01-24 07:19:54.075130]  Downloaded False to /content/input/abrehamatlaw0-spinoza-ds-datapreparer-simsim-cum-0-it-2-0 \u001b[0m\n",
      "\u001b[94m PID:191 [2025-01-24 07:19:54.075393]  Generating checksum for '/content/input/abrehamatlaw0-spinoza-ds-datapreparer-simsim-cum-0-it-2-0' \u001b[0m\n",
      "\u001b[94m PID:191 [2025-01-24 07:19:54.133613]  Checksum: 5ebd5e25271009a2ef34ab8be424bd705a1862f1c1b935f7b926c98f56ab6338 \u001b[0m\n",
      "\u001b[94m PID:191 [2025-01-24 07:19:54.134953]  Downloading abrehamatlaw0/spinoza-ds-datapreparer-simsim-cum-0-it-2-1 \u001b[0m\n",
      "\u001b[94m PID:191 [2025-01-24 07:19:54.135107]  Downloading to /content/input/abrehamatlaw0-spinoza-ds-datapreparer-simsim-cum-0-it-2-1 \u001b[0m\n",
      "\u001b[94m PID:191 [2025-01-24 07:19:54.135209]  Checking pre-downloaded for /content/input/abrehamatlaw0-spinoza-ds-datapreparer-simsim-cum-0-it-2-1 \u001b[0m\n",
      "\u001b[94m PID:191 [2025-01-24 07:19:54.140108]  Cleaning /content/input/abrehamatlaw0-spinoza-ds-datapreparer-simsim-cum-0-it-2-1 \u001b[0m\n",
      "Dataset URL: https://www.kaggle.com/datasets/abrehamatlaw0/spinoza-ds-datapreparer-simsim-cum-0-it-2-1\n",
      "\u001b[94m PID:191 [2025-01-24 07:19:56.357189]  Unzipping Data... \u001b[0m\n",
      "\u001b[94m PID:191 [2025-01-24 07:21:19.035819]  Downloaded False to /content/input/abrehamatlaw0-spinoza-ds-datapreparer-simsim-cum-0-it-2-1 \u001b[0m\n",
      "\u001b[94m PID:191 [2025-01-24 07:21:19.036092]  Generating checksum for '/content/input/abrehamatlaw0-spinoza-ds-datapreparer-simsim-cum-0-it-2-1' \u001b[0m\n",
      "\u001b[94m PID:191 [2025-01-24 07:21:19.084416]  Checksum: 4a449396071a53e821063d191e868c48323afa0431e95022cf697f79c0d169b1 \u001b[0m\n",
      "\u001b[94m PID:191 [2025-01-24 07:21:19.086339]  Downloading abrehamatlaw0/spinoza-ds-datapreparer-simsim-cum-0-it-2-2 \u001b[0m\n",
      "\u001b[94m PID:191 [2025-01-24 07:21:19.087708]  Downloading to /content/input/abrehamatlaw0-spinoza-ds-datapreparer-simsim-cum-0-it-2-2 \u001b[0m\n",
      "\u001b[94m PID:191 [2025-01-24 07:21:19.090501]  Checking pre-downloaded for /content/input/abrehamatlaw0-spinoza-ds-datapreparer-simsim-cum-0-it-2-2 \u001b[0m\n",
      "\u001b[94m PID:191 [2025-01-24 07:21:19.092121]  Cleaning /content/input/abrehamatlaw0-spinoza-ds-datapreparer-simsim-cum-0-it-2-2 \u001b[0m\n",
      "Dataset URL: https://www.kaggle.com/datasets/abrehamatlaw0/spinoza-ds-datapreparer-simsim-cum-0-it-2-2\n",
      "\u001b[94m PID:191 [2025-01-24 07:21:21.001815]  Unzipping Data... \u001b[0m\n",
      "\u001b[94m PID:191 [2025-01-24 07:22:52.003750]  Downloaded False to /content/input/abrehamatlaw0-spinoza-ds-datapreparer-simsim-cum-0-it-2-2 \u001b[0m\n",
      "\u001b[94m PID:191 [2025-01-24 07:22:52.004107]  Generating checksum for '/content/input/abrehamatlaw0-spinoza-ds-datapreparer-simsim-cum-0-it-2-2' \u001b[0m\n",
      "\u001b[94m PID:191 [2025-01-24 07:22:52.057465]  Checksum: 12224459b7e75921cc5173e56444654ebf1dd0e6551f4fc7c917a728399d3984 \u001b[0m\n",
      "\u001b[94m PID:191 [2025-01-24 07:22:52.057671]  Downloading abrehamatlaw0/spinoza-ds-datapreparer-simsim-cum-0-it-2-3 \u001b[0m\n",
      "\u001b[94m PID:191 [2025-01-24 07:22:52.060775]  Downloading to /content/input/abrehamatlaw0-spinoza-ds-datapreparer-simsim-cum-0-it-2-3 \u001b[0m\n",
      "\u001b[94m PID:191 [2025-01-24 07:22:52.060907]  Checking pre-downloaded for /content/input/abrehamatlaw0-spinoza-ds-datapreparer-simsim-cum-0-it-2-3 \u001b[0m\n",
      "\u001b[94m PID:191 [2025-01-24 07:22:52.065015]  Cleaning /content/input/abrehamatlaw0-spinoza-ds-datapreparer-simsim-cum-0-it-2-3 \u001b[0m\n",
      "Dataset URL: https://www.kaggle.com/datasets/abrehamatlaw0/spinoza-ds-datapreparer-simsim-cum-0-it-2-3\n",
      "\u001b[94m PID:191 [2025-01-24 07:22:54.253881]  Unzipping Data... \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "DATA_ROOT = \"/kaggle/input\" if KAGGLE_ENV else \"/content/input\"\n",
    "\n",
    "DATASETS = [\n",
    "    f\"abrehamatlaw0/spinoza-ds-datapreparer-simsim-cum-0-it-36-0\"\n",
    "]\n",
    "CHECKSUMS = [\n",
    "    '52679b000c348fab8e9901a91f8e07f6e857c4fa90f6358e62269f37818a6b9d',\n",
    "]\n",
    "KERNEL_MODE = False\n",
    "ZIP_FILENAME = \"out.zip\"\n",
    "if not KAGGLE_ENV:\n",
    "    download_data(DATA_ROOT, DATASETS, ZIP_FILENAME, kernel_mode=KERNEL_MODE, checksums=CHECKSUMS)\n",
    "\n",
    "\n",
    "CONTAINERS = [os.path.join(DATA_ROOT, container) for container in os.listdir(DATA_ROOT)]\n",
    "DATA_PATHES, TEST_DATA_PATHES = [\n",
    "    [\n",
    "        os.path.join(container, \"out\", type_)\n",
    "        for container in CONTAINERS\n",
    "    ]\n",
    "    for type_ in [\"train\", \"test\"]\n",
    "]\n",
    "\n",
    "NOTEBOOK_ID = \"abrehamalemu/rtrader-training-exp-0-cnn-0-cum-0-it-36-tot\"\n",
    "MODEL_ID = NOTEBOOK_ID.replace(\"/\", \"-\")\n",
    "\n",
    "NUM_FILES = None\n",
    "DATA_CACHE_SIZE = 2\n",
    "DATALOADER_WORKERS = 4\n",
    "\n",
    "LR = 1e-4\n",
    "\n",
    "LOSS_P = 1\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 100\n",
    "TIMEOUT = 10*60*60\n",
    "\n",
    "DTYPE = torch.float32\n",
    "NP_DTYPE = np.float32\n",
    "\n",
    "MODEL_URL = None\n",
    "SAVE_PATH = os.path.abspath(f\"./out/{MODEL_ID}.zip\")\n",
    "STATE_SAVE_PATH = os.path.abspath(\"./out/model.zip\")\n",
    "UPLOAD_PATH = \"/Apps/RTrader/maploss/it-36/\"\n",
    "\n",
    "METRIC_REPOSITORY = MongoDBMetricRepository(\n",
    "    Config.MONGODB_URL,\n",
    "    MODEL_ID\n",
    ")\n",
    "\n",
    "CALLBACKS = [\n",
    "    StoreCheckpointCallback(\n",
    "        path=os.path.dirname(SAVE_PATH),\n",
    "        active=True, \n",
    "        interval=5,\n",
    "        fs=ServiceProvider.provide_file_storage(UPLOAD_PATH)\n",
    "    ),\n",
    "    MetricCallback(\n",
    "       METRIC_REPOSITORY\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AAPzrnlUK-lS"
   },
   "outputs": [],
   "source": [
    "repository = CheckpointRepository(\n",
    "    ServiceProvider.provide_file_storage()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kbNrtcqTK-lS"
   },
   "outputs": [],
   "source": [
    "state_model = repository.get(MODEL_ID)\n",
    "# state_model = None\n",
    "if state_model is None:\n",
    "    raise ValueError(\"Can't Find Model\")\n",
    "\n",
    "else:\n",
    "    print(\"[+]Using loaded model...\")\n",
    "    state, model = state_model\n",
    "state = TrainingState(\n",
    "    epoch=0,\n",
    "    batch=0,\n",
    "    id=MODEL_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-bacoyFoK-lT"
   },
   "outputs": [],
   "source": [
    "dataset = BaseDataset(\n",
    "    root_dirs=DATA_PATHES,\n",
    "    out_dtypes=NP_DTYPE,\n",
    "    num_files=NUM_FILES,\n",
    "    check_file_sizes=True,\n",
    "    load_weights=True\n",
    ")\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, num_workers=DATALOADER_WORKERS, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jgsW_nQ1K-lW"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(model, callbacks=CALLBACKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YdobrgSLK-lX"
   },
   "outputs": [],
   "source": [
    "trainer.cls_loss_function = ProximalMaskedLoss(\n",
    "    n=len(Config.AGENT_STATE_CHANGE_DELTA_STATIC_BOUND) + 1 ,\n",
    "    p=LOSS_P,\n",
    "    softmax=True,\n",
    "    device=trainer.device,\n",
    ")\n",
    "trainer.reg_loss_function = MeanSquaredErrorLoss()\n",
    "trainer.optimizer = Adam(trainer.model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qMtSify1K-lZ"
   },
   "outputs": [],
   "source": [
    "class TimeoutException(Exception):\n",
    "    pass\n",
    "\n",
    "def handle_timeout(*args, **kwargs):\n",
    "    raise TimeoutException()\n",
    "\n",
    "signal.signal(signal.SIGALRM, handle_timeout)\n",
    "signal.alarm(TIMEOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "poLTWAztK-lZ"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    trainer.train(dataloader, epochs=EPOCHS, progress=True, progress_interval=1000, state=state, cls_loss_only=False)\n",
    "except TimeoutException:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xl2WMZpiK-lZ"
   },
   "outputs": [],
   "source": [
    "ModelHandler.save(model, SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HkPf9xkLK-la"
   },
   "outputs": [],
   "source": [
    "repository.update(trainer.state, trainer.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ApxMgaNgK-la"
   },
   "outputs": [],
   "source": [
    "metrics = MetricsContainer()\n",
    "for metric in METRIC_REPOSITORY.get_all():\n",
    "    metrics.add_metric(metric)\n",
    "\n",
    "for i in range(3):\n",
    "    train_losses = [metric.value[i] for metric in metrics.filter_metrics(source=0)]\n",
    "    val_losses = [metric.value[i] for metric in metrics.filter_metrics(source=1)]\n",
    "    plt.figure()\n",
    "    plt.plot(train_losses)\n",
    "    plt.plot(val_losses)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nYVd0TJnK-lb"
   },
   "outputs": [],
   "source": [
    "for X, y in test_dataloader:\n",
    "    break\n",
    "y_hat = model(X.to(trainer.device)).detach().cpu().numpy()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x))\n",
    "    softmax_x = exp_x / np.sum(exp_x)\n",
    "    return softmax_x\n",
    "\n",
    "def scale(x):\n",
    "    x = softmax(x)\n",
    "    x = x / np.max(x)\n",
    "    return x\n",
    "\n",
    "for i in range(y_hat.shape[0]):\n",
    "    plt.figure()\n",
    "    plt.plot(y[i, :-1])\n",
    "    plt.plot(scale(y_hat[i, :-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tpA11eD0K-lb"
   },
   "outputs": [],
   "source": [
    "!rm -fr r_trader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RhDWVVZ4K-lc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 199105437,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 199602130,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 199602285,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 199602296,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
