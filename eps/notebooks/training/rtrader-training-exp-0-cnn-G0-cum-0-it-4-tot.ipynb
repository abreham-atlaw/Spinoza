{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "!rm -fr r_trader out\n",
    "!mkdir out input\n",
    "!git clone https://github.com/abreham-atlaw/r_trader\n",
    "!cd r_trader &&  git checkout deep-reinforcement.training-experiment-cnn\n",
    "!pip install cattrs positional-encodings==6.0.1 dropbox pymongo==4.3.3 dependency-injector==4.41.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "KAGGLE_ENV = os.path.exists(\"/kaggle/working\")\n",
    "REPO_PATH = \"/kaggle/working/r_trader\" if KAGGLE_ENV else \"/content/r_trader\"\n",
    "\n",
    "print(f\"KAGGLE ENV: {KAGGLE_ENV}\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(REPO_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam, SGD, Adagrad\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import signal \n",
    "\n",
    "from core.utils.research.data.load.dataset import BaseDataset\n",
    "from core.utils.research.training.trainer import Trainer\n",
    "from core.utils.research.model.model.cnn.model import CNN\n",
    "from core.utils.research.model.model.linear.model import LinearModel\n",
    "from lib.utils.torch_utils.model_handler import ModelHandler\n",
    "from core.utils.research.training.callbacks.checkpoint_callback import CheckpointCallback, StoreCheckpointCallback\n",
    "from core.utils.research.training.data.repositories.checkpoint_repository import CheckpointRepository\n",
    "from lib.utils.file_storage import PCloudClient\n",
    "from core.utils.research.training.data.state import TrainingState\n",
    "from core import Config\n",
    "from core.utils.research.training.callbacks.metric_callback import MetricCallback\n",
    "from core.utils.research.training.data.repositories.metric_repository import MetricRepository, MongoDBMetricRepository\n",
    "from core.utils.kaggle import FusedManager\n",
    "from core.di import init_di, ApplicationContainer\n",
    "from core.utils.research.training.data.metric import MetricsContainer\n",
    "from core.utils.research.model.layers import Indicators\n",
    "from core.di import ServiceProvider\n",
    "from core.utils.kaggle.data_repository import KaggleDataRepository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(root, datasets, zip_filename, kernel_mode=True, checksums=None):\n",
    "    repository = KaggleDataRepository(\n",
    "        output_path=root,\n",
    "        zip_filename=zip_filename\n",
    "    )\n",
    "    repository.download_multiple(datasets, kernel=kernel_mode, checksums=checksums)\n",
    "    os.system(f\"unzip -d root/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = \"/kaggle/input\" if KAGGLE_ENV else \"/content/input\"\n",
    "\n",
    "DATASETS = [\n",
    "    f\"abrehamatlaw0/spinoza-ds-datapreparer-simsim-cum-0-it-2-{i}\"\n",
    "    for i in range(0,4)\n",
    "]\n",
    "CHECKSUMS = None\n",
    "KERNEL_MODE = False\n",
    "ZIP_FILENAME = \"out.zip\"\n",
    "if not KAGGLE_ENV:\n",
    "    download_data(DATA_ROOT, DATASETS, ZIP_FILENAME, kernel_mode=KERNEL_MODE, checksums=CHECKSUMS)\n",
    "\n",
    "\n",
    "CONTAINERS = [os.path.join(DATA_ROOT, container) for container in os.listdir(DATA_ROOT)]\n",
    "DATA_PATHES, TEST_DATA_PATHES = [\n",
    "    [\n",
    "        os.path.join(container, \"out\", type_)\n",
    "        for container in CONTAINERS\n",
    "    ]\n",
    "    for type_ in [\"train\", \"test\"]\n",
    "]\n",
    "\n",
    "NOTEBOOK_ID = \"abrehamalemu/rtrader-training-exp-0-cnn-150-cum-0-it-4-tot\"\n",
    "MODEL_ID = NOTEBOOK_ID.replace(\"/\", \"-\")\n",
    "\n",
    "NUM_FILES = None\n",
    "DATA_CACHE_SIZE = 2\n",
    "DATALOADER_WORKERS = 4\n",
    "\n",
    "LOSS_P = 1\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "TIMEOUT = 10*60*60\n",
    "\n",
    "DTYPE = torch.float32\n",
    "NP_DTYPE = np.float32\n",
    "\n",
    "MODEL_URL = None\n",
    "SAVE_PATH = os.path.abspath(\"./out/model.zip\")\n",
    "STATE_SAVE_PATH = os.path.abspath(\"./out/model.zip\")\n",
    "\n",
    "METRIC_REPOSITORY = MongoDBMetricRepository(\n",
    "    Config.MONGODB_URL,\n",
    "    MODEL_ID\n",
    ")\n",
    "\n",
    "CALLBACKS = [\n",
    "    StoreCheckpointCallback(path=SAVE_PATH),\n",
    "    MetricCallback(\n",
    "       METRIC_REPOSITORY\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repository = CheckpointRepository(\n",
    "    ServiceProvider.provide_file_storage()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_model = repository.get(MODEL_ID)\n",
    "# state_model = None\n",
    "if state_model is None:\n",
    "    raise ValueError(\"Can't Find Model\")\n",
    "    \n",
    "else:\n",
    "    print(\"[+]Using loaded model...\")\n",
    "    state, model = state_model\n",
    "state = TrainingState(\n",
    "    epoch=0,\n",
    "    batch=0,\n",
    "    id=MODEL_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BaseDataset(\n",
    "    root_dirs=DATA_PATHES,\n",
    "    out_dtypes=NP_DTYPE,\n",
    "    num_files=NUM_FILES\n",
    ")\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, num_workers=DATALOADER_WORKERS, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = BaseDataset(\n",
    "    root_dirs=TEST_DATA_PATHES, \n",
    "    out_dtypes=NP_DTYPE,\n",
    "    num_files=NUM_FILES\n",
    ")\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=DATALOADER_WORKERS, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, callbacks=CALLBACKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.cls_loss_function = ProximalMaskedLoss(\n",
    "    n=len(Config.AGENT_STATE_CHANGE_DELTA_STATIC_BOUND) + 1 ,\n",
    "    p=LOSS_P,\n",
    "    softmax=True,\n",
    "    device=trainer.device,\n",
    "    \n",
    ")\n",
    "trainer.reg_loss_function = nn.MSELoss()\n",
    "trainer.optimizer = Adam(trainer.model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeoutException(Exception):\n",
    "    pass\n",
    "\n",
    "def handle_timeout(*args, **kwargs):\n",
    "    raise TimeoutException()\n",
    "\n",
    "signal.signal(signal.SIGALRM, handle_timeout)\n",
    "signal.alarm(TIMEOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    trainer.train(dataloader, val_dataloader=test_dataloader, epochs=EPOCHS, progress=True, progress_interval=100, state=state, cls_loss_only=False)\n",
    "except TimeoutException:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelHandler.save(model, SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repository.update(trainer.state, trainer.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = MetricsContainer()\n",
    "for metric in METRIC_REPOSITORY.get_all():\n",
    "    metrics.add_metric(metric)\n",
    "\n",
    "for i in range(3):\n",
    "    train_losses = [metric.value[i] for metric in metrics.filter_metrics(source=0)]\n",
    "    val_losses = [metric.value[i] for metric in metrics.filter_metrics(source=1)]\n",
    "    plt.figure()\n",
    "    plt.plot(train_losses)\n",
    "    plt.plot(val_losses)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for X, y in test_dataloader:\n",
    "    break\n",
    "y_hat = model(X.to(trainer.device)).detach().cpu().numpy()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x))\n",
    "    softmax_x = exp_x / np.sum(exp_x)\n",
    "    return softmax_x\n",
    "\n",
    "def scale(x):\n",
    "    x = softmax(x)\n",
    "    x = x / np.max(x)\n",
    "    return x\n",
    "\n",
    "for i in range(y_hat.shape[0]):\n",
    "    plt.figure()\n",
    "    plt.plot(y[i, :-1])\n",
    "    plt.plot(scale(y_hat[i, :-1]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -fr r_trader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 199105437,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 199602130,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 199602285,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 199602296,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
