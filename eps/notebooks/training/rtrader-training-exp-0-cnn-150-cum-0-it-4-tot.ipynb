{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":199105437,"sourceType":"kernelVersion"},{"sourceId":199602130,"sourceType":"kernelVersion"},{"sourceId":199602285,"sourceType":"kernelVersion"},{"sourceId":199602296,"sourceType":"kernelVersion"}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!rm -fr r_trader out\n!mkdir out input\n!git clone https://github.com/abreham-atlaw/r_trader\n!cd r_trader &&  git checkout deep-reinforcement.training-experiment-cnn\n!pip install cattrs positional-encodings==6.0.1 dropbox pymongo==4.3.3 dependency-injector==4.41.0","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nKAGGLE_ENV = os.path.exists(\"/kaggle/working\")\nREPO_PATH = \"/kaggle/working/r_trader\" if KAGGLE_ENV else \"/content/r_trader\"\n\nprint(f\"KAGGLE ENV: {KAGGLE_ENV}\")\n\nimport sys\nsys.path.append(REPO_PATH)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torch.optim import Adam, SGD, Adagrad\nimport matplotlib.pyplot as plt\n\nimport os\nimport signal \n\nfrom core.utils.research.data.load.dataset import BaseDataset\nfrom core.utils.research.training.trainer import Trainer\nfrom core.utils.research.model.model.cnn.model import CNN\nfrom core.utils.research.model.model.linear.model import LinearModel\nfrom lib.utils.torch_utils.model_handler import ModelHandler\nfrom core.utils.research.training.callbacks.checkpoint_callback import CheckpointCallback, StoreCheckpointCallback\nfrom core.utils.research.training.data.repositories.checkpoint_repository import CheckpointRepository\nfrom lib.utils.file_storage import PCloudClient\nfrom core.utils.research.training.data.state import TrainingState\nfrom core import Config\nfrom core.utils.research.training.callbacks.metric_callback import MetricCallback\nfrom core.utils.research.training.data.repositories.metric_repository import MetricRepository, MongoDBMetricRepository\nfrom core.utils.kaggle import FusedManager\nfrom core.di import init_di, ApplicationContainer\nfrom core.utils.research.training.data.metric import MetricsContainer\nfrom core.utils.research.model.layers import Indicators\nfrom core.di import ServiceProvider\nfrom core.utils.kaggle.data_repository import KaggleDataRepository","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def download_data(root, datasets, zip_filename, kernel_mode=True, checksums=None):\n    repository = KaggleDataRepository(\n        output_path=root,\n        zip_filename=zip_filename\n    )\n    repository.download_multiple(datasets, kernel=kernel_mode, checksums=checksums)\n    os.system(f\"unzip -d root/\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"DATA_ROOT = \"/kaggle/input\" if KAGGLE_ENV else \"/content/input\"\n\nDATASETS = [\n    f\"abrehamatlaw0/spinoza-ds-datapreparer-simsim-cum-0-it-2-{i}\"\n    for i in range(0,4)\n]\nCHECKSUMS = None\nKERNEL_MODE = False\nZIP_FILENAME = \"out.zip\"\nif not KAGGLE_ENV:\n    download_data(DATA_ROOT, DATASETS, ZIP_FILENAME, kernel_mode=KERNEL_MODE, checksums=CHECKSUMS)\n\n\nCONTAINERS = [os.path.join(DATA_ROOT, container) for container in os.listdir(DATA_ROOT)]\nDATA_PATHES, TEST_DATA_PATHES = [\n    [\n        os.path.join(container, \"out\", type_)\n        for container in CONTAINERS\n    ]\n    for type_ in [\"train\", \"test\"]\n]\n\nNOTEBOOK_ID = \"abrehamalemu/rtrader-training-exp-0-cnn-150-cum-0-it-4-tot\"\nMODEL_ID = NOTEBOOK_ID.replace(\"/\", \"-\")\n\nNUM_FILES = None\nDATA_CACHE_SIZE = 2\nDATALOADER_WORKERS = 4\n\nCHANNELS = [128 for _ in range(1)]\nEXTRA_LEN = 124\nKERNEL_SIZES = [3 for _ in CHANNELS]\nVOCAB_SIZE = 431\nPOOL_SIZES = [3 for _ in CHANNELS]\nDROPOUT_RATE = 0\nACTIVATION = nn.LeakyReLU()\nBLOCK_SIZE = 1024 + EXTRA_LEN\nPADDING = 0\nLINEAR_COLLAPSE = True\nAVG_POOL = True\nNORM = [False] + [False for _ in CHANNELS[1:]]\nLR = 1e-5\n\nINDICATORS_DELTA = True\nINDICATORS_SO = []\nINDICATORS_RSI = []\n\nUSE_FF = True\nFF_LINEAR_LAYERS = [4096 for _ in range(4)] + [VOCAB_SIZE + 1]\nFF_LINEAR_ACTIVATION = nn.LeakyReLU()\nFF_LINEAR_INIT = None\nFF_LINEAR_NORM = [False] + [False for _ in FF_LINEAR_LAYERS[:-1]]\nFF_DROPOUT = 0.3\n\nBATCH_SIZE = 64\nEPOCHS = 100\nTIMEOUT = 10*60*60\n\nDTYPE = torch.float32\nNP_DTYPE = np.float32\n\nMODEL_URL = None\nSAVE_PATH = os.path.abspath(\"./out/model.zip\")\nSTATE_SAVE_PATH = os.path.abspath(\"./out/model.zip\")\n\nMETRIC_REPOSITORY = MongoDBMetricRepository(\n    Config.MONGODB_URL,\n    MODEL_ID\n)\n\nCALLBACKS = [\n    StoreCheckpointCallback(path=SAVE_PATH),\n    MetricCallback(\n       METRIC_REPOSITORY\n    )\n]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"repository = CheckpointRepository(\n    ServiceProvider.provide_file_storage()\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"state_model = repository.get(MODEL_ID)\n# state_model = None\nif state_model is None:\n    print(\"[+]Creating a new model...\")\n    if USE_FF:\n        ff = LinearModel(\n            dropout_rate=FF_DROPOUT,\n            layer_sizes=FF_LINEAR_LAYERS,\n            hidden_activation=FF_LINEAR_ACTIVATION,\n            init_fn=FF_LINEAR_INIT,\n            norm=FF_LINEAR_NORM\n        )\n    else:\n        ff = None\n\n    indicators = Indicators(\n        delta=INDICATORS_DELTA,\n        so=INDICATORS_SO,\n        rsi=INDICATORS_RSI\n    )\n\n    model = CNN(\n        extra_len=EXTRA_LEN,\n        conv_channels=CHANNELS,\n        kernel_sizes=KERNEL_SIZES,\n        hidden_activation=ACTIVATION,\n        pool_sizes=POOL_SIZES,\n        dropout_rate=DROPOUT_RATE,\n        padding=PADDING,\n        avg_pool=AVG_POOL,\n        linear_collapse=LINEAR_COLLAPSE,\n        norm=NORM,\n        ff_block=ff,\n        indicators=indicators,\n        input_size=BLOCK_SIZE\n    )\n    \nelse:\n    print(\"[+]Using loaded model...\")\n    state, model = state_model\nstate = TrainingState(\n    epoch=0,\n    batch=0,\n    id=MODEL_ID\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset = BaseDataset(\n    root_dirs=DATA_PATHES,\n    out_dtypes=NP_DTYPE,\n    num_files=NUM_FILES\n)\ndataloader = DataLoader(dataset, batch_size=BATCH_SIZE, num_workers=DATALOADER_WORKERS, pin_memory=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_dataset = BaseDataset(\n    root_dirs=TEST_DATA_PATHES, \n    out_dtypes=NP_DTYPE,\n    num_files=NUM_FILES\n)\ntest_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=DATALOADER_WORKERS, pin_memory=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer = Trainer(model, callbacks=CALLBACKS)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.cls_loss_function = nn.CrossEntropyLoss()\ntrainer.reg_loss_function = nn.MSELoss()\ntrainer.optimizer = Adam(trainer.model.parameters(), lr=LR)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class TimeoutException(Exception):\n    pass\n\ndef handle_timeout(*args, **kwargs):\n    raise TimeoutException()\n\nsignal.signal(signal.SIGALRM, handle_timeout)\nsignal.alarm(TIMEOUT)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"try:\n    trainer.train(dataloader, val_dataloader=test_dataloader, epochs=EPOCHS, progress=True, progress_interval=100, state=state, cls_loss_only=False)\nexcept TimeoutException:\n    pass","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ModelHandler.save(model, SAVE_PATH)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"repository.update(trainer.state, trainer.model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"metrics = MetricsContainer()\nfor metric in METRIC_REPOSITORY.get_all():\n    metrics.add_metric(metric)\n\nfor i in range(3):\n    train_losses = [metric.value[i] for metric in metrics.filter_metrics(source=0)]\n    val_losses = [metric.value[i] for metric in metrics.filter_metrics(source=1)]\n    plt.figure()\n    plt.plot(train_losses)\n    plt.plot(val_losses)\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for X, y in test_dataloader:\n    break\ny_hat = model(X.to(trainer.device)).detach().cpu().numpy()\n\nimport matplotlib.pyplot as plt\ndef softmax(x):\n    exp_x = np.exp(x - np.max(x))\n    softmax_x = exp_x / np.sum(exp_x)\n    return softmax_x\n\ndef scale(x):\n    x = softmax(x)\n    x = x / np.max(x)\n    return x\n\nfor i in range(y_hat.shape[0]):\n    plt.figure()\n    plt.plot(y[i, :-1])\n    plt.plot(scale(y_hat[i, :-1]))\n    ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!rm -fr r_trader","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}